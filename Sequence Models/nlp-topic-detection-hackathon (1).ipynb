{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings\nnp.random.seed(1234)\nwarnings.filterwarnings('ignore')\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to see how well this approach works for our dataset. I would also like to point out that all these ideas and code are available at fast.ai's free official course for NLP - \"\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = pd.read_csv(\"/kaggle/input/independence-hacakathon/train.csv\", delimiter=\",\")\ntrain_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = pd.read_csv(\"/kaggle/input/independence-hacakathon/test.csv\", delimiter=\",\")\ntest_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = train_dataset.copy()\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Review_Combined'] = dataset['TITLE'] + \". \" + dataset['ABSTRACT']\ndataset['Review_Combined'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset['Review_Combined'] = test_dataset['TITLE'] + \". \" + test_dataset['ABSTRACT']\ntest_dataset['Review_Combined'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install fastai2\nfrom fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.to_csv(\"/kaggle/working/train.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/independence-hacakathon/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data in fast.ai is taken using TextLMDataBunch. This is very similar to ImageGenerator in Keras, where the path, labels, etc. are provided and the method prepares Train, Test and Validation data depending on the task at hand!"},{"metadata":{},"cell_type":"markdown","source":"## Data Bunch for Language Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n#%%time\ndata_lm = TextLMDataBunch.from_csv(path,'train.csv', text_cols = \"ABSTRACT\", label_cols = labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Bunch for Classification Task"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\ndata_clas = TextClasDataBunch.from_csv(path, csv_name = 'train.csv', test = 'test.csv', vocab=data_lm.train_ds.vocab, bs=16, text_cols = \"ABSTRACT\", label_cols = labels, valid_pct = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#torch.cuda.set_device(1)\n#torch.cuda.set_device(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1. Training a Language Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discrimiative Fine-Tuning"},{"metadata":{},"cell_type":"markdown","source":"*learn.unfreeze()* makes all the layers of AWD_LSTM trainable. We can set a training rate using slice() function, which trains the last layer at 1e-02, while groups (of layers) in between would have geometrically reducing learning rates."},{"metadata":{},"cell_type":"markdown","source":"### Slated Triangular Learning Rates"},{"metadata":{},"cell_type":"markdown","source":"This can achieved simply by using fit_one_cycle() method in fast.ai"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"### Gradual Unfreezing"},{"metadata":{},"cell_type":"markdown","source":"Though I've not experimented with this here, the idea is pretty simple. In the start we keep the initial layers of model as un-trainable, and then we slowly unfreeze earlier layers, as we keep on training. I'll cover this in detail in next post"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(1e-4,1e-2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(\"This is a review about\", n_words=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(\"This game is one of the \", n_words=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This performs pretty well in predicting the next few words of the review. Time to save this and try it on our classification task."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model_dir = Path('/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save(file = Path('language_model'))\nlearn.save_encoder(Path('language_model_encoder'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 2. Classification Task using Language Model as encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"F1_01 = MultiLabelFbeta(beta=1, average=\"micro\", thresh = 0.1)\nF1_03 = MultiLabelFbeta(beta=1, average=\"micro\", thresh = 0.3)\nF1_05 = MultiLabelFbeta(beta=1, average=\"micro\", thresh = 0.5)\n#learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, error_rate, F1_01, F1_03, F1_05]).to_fp16()\nlearn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics=[accuracy, error_rate, F1_01, F1_03, F1_05])\nlearn.model_dir = Path('/kaggle/working/')\nlearn.load_encoder('language_model_encoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.freeze_to(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 5e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.freeze_to(-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.fit_one_cycle(1, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.freeze_to(-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.fit_one_cycle(1, 5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds_as_nparray(ds_type) -> np.ndarray:\n    \"\"\"\n    the get_preds method does not yield the elements in order by default\n    we borrow the code from the RNNLearner to resort the elements into their correct order\n    \"\"\"\n    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n    sampler = [i for i in data_clas.dl(ds_type).sampler]\n    reverse_sampler = np.argsort(sampler)\n    return preds[reverse_sampler, :]\n\n#test_preds = get_preds_as_nparray(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(5, slice(1e-4, 1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = learn.get_preds(DatasetType.Test)[0].detach().cpu().numpy()\ntest_preds = preds1.copy()\n\nthresh = 0.3\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_phase1_layer1_\" + str(thresh) + \".csv\", index=True)\n\nthresh = 0.5\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_phase1_layer1_\" + str(thresh) + \".csv\", index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(5, slice(1e-5, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = learn.get_preds(DatasetType.Test)[0].detach().cpu().numpy()\ntest_preds = preds1.copy()\n\nthresh = 0.3\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_phase1_layer2_\" + str(thresh) + \".csv\", index=True)\n\nthresh = 0.5\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_phase1_layer2_\" + str(thresh) + \".csv\", index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.lr_find()\n#learn.recorder.plot(skip_end=10,suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.unfreeze()\n#learn.fit_one_cycle(4, slice(1e-6, 1e-5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.lr_find()\n#learn.recorder.plot(skip_end=10,suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, slice(1e-6, 1e-5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds_as_nparray(ds_type) -> np.ndarray:\n    \"\"\"\n    the get_preds method does not yield the elements in order by default\n    we borrow the code from the RNNLearner to resort the elements into their correct order\n    \"\"\"\n    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n    sampler = [i for i in data_clas.dl(ds_type).sampler]\n    reverse_sampler = np.argsort(sampler)\n    return preds[reverse_sampler, :]\n\n#test_preds = get_preds_as_nparray(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = learn.get_preds(DatasetType.Test)[0].detach().cpu().numpy()\n#preds2 = get_preds_as_nparray(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = preds1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(test_preds).to_csv(\"/kaggle/working/output.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = 0.3\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_layer2_\" + str(thresh) + \".csv\", index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = 0.5\ntest_preds2 = test_preds.copy()\ntest_preds2[test_preds2<=thresh] = 0\ntest_preds2[test_preds2>thresh] = 1\nx = pd.DataFrame(test_preds2, columns = labels)\nx.index = test_dataset['ID']\nx.to_csv(\"predictions_awd_lstm_new_layer2_\" + str(thresh) + \".csv\", index=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}