{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings\nnp.random.seed(123)\nwarnings.filterwarnings('ignore')\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading train and test file\n\ntrain = pd.read_csv(\"/kaggle/input/jantahack-recommender-systems/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/jantahack-recommender-systems/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the train in the long format to wide format\n\nwide_train = train.pivot_table(index = \"user_id\", columns=\"challenge_sequence\", values=\"challenge\", aggfunc= lambda x : x).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the user_id, since we won't be needing those for our co-occurrence matrix\n\nwide_train.drop([\"user_id\"], axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert each row for a user into a string\n\nrows = []\nfor index, row in wide_train.iterrows():\n    r = \" \".join(row.map(str)).lower()\n    rows.append(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting test to wide format\n\nwide_test = test.pivot_table(index = \"user_id\", columns=\"challenge_sequence\", values=\"challenge\", aggfunc= lambda x : x).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wide_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving test user_id for future use\n\ntest_ids = wide_test['user_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping user_id from wide test\n\nwide_test.drop([\"user_id\"], axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in wide_test.iterrows():\n    r = \" \".join(row.map(str)).lower()\n    rows.append(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data in fast.ai is taken using TextLMDataBunch. This is very similar to ImageGenerator in Keras, where the path, labels, etc. are provided and the method prepares Train, Test and Validation data depending on the task at hand!"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rows).to_csv('/kaggle/working/new_corpus.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Bunch for Language Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a corpus\nthefile = open(\"corpus.txt\",\"w\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for element in rows:\n    thefile.write(\"%s\\n\"%element)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thefile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata_lm = TextLMDataBunch.from_csv(path,'new_corpus.csv', text_cols = 0, include_bos = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#torch.cuda.set_device(1)\n#torch.cuda.set_device(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1. Training a Language Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.callbacks.append(ShowGraph(learn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot(skip_end=10,suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4, 4e-2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discrimiative Fine-Tuning"},{"metadata":{},"cell_type":"markdown","source":"*learn.unfreeze()* makes all the layers of AWD_LSTM trainable. We can set a training rate using slice() function, which trains the last layer at 1e-02, while groups (of layers) in between would have geometrically reducing learning rates."},{"metadata":{},"cell_type":"markdown","source":"### Slated Triangular Learning Rates"},{"metadata":{},"cell_type":"markdown","source":"This can achieved simply by using fit_one_cycle() method in fast.ai"},{"metadata":{},"cell_type":"markdown","source":"### Gradual Unfreezing"},{"metadata":{},"cell_type":"markdown","source":"Though I've not experimented with this here, the idea is pretty simple. In the start we keep the initial layers of model as un-trainable, and then we slowly unfreeze earlier layers, as we keep on training. I'll cover this in detail in next post"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(skip_end=10,suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(skip_end=10,suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, slice(1e-4, 1e-2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, slice(1e-4, 1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model_dir = Path('/kaggle/working/')\nlearn.save(file = Path('language_model'))\nlearn.save_encoder(Path('language_model_encoder'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\nlearn.model_dir = Path('/kaggle/input/modelencoder/')\nlearn.load_encoder('language_model_encoder (3)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(rows[2], n_words=6).upper()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_rows = []\nfor index, row in wide_test.iterrows():\n    r = \" \".join(row.map(str)).lower()\n    test_rows.append(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntext = test_rows[2]\nlearn.predict(text, n_words = 1, temperature = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pred(text):\n    result = learn.predict(text, n_words = 3, temperature = 0.2)\n    all_words = result.upper().split(\" \")\n    #print(result)\n    outputs = list(all_words[10:13])\n    return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pred2(text, num_pred):\n    \n    start = text\n    initial_words = text.split(\" \")\n    current_words = initial_words\n    \n    for i in range(0, num_pred):\n        output = learn.predict(start, n_words = 1, temperature = 0.2)\n        all_words = output.split(\" \")\n        count = 0\n        while(all_words[-1] in current_words):\n            count = count+1\n            output = learn.predict(start, n_words = 1, temperature = 0.2)\n            all_words = output.split(\" \")\n            if(count > 2):\n                break;\n            #print(count)\n        start = output\n        current_words = all_words\n    \n    #print(output)\n    pred = list(output.upper().split(\" \")[10:13])\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_rows[2].upper()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nget_pred(test_rows[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nget_pred2(test_rows[2], 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_fastai = []\nfor i in range(19500,39732):\n    print(i)\n    preds = get_pred2(test_rows[i], 3)\n    preds_fastai.append(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids[19500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"largest_3 = pd.DataFrame(preds_fastai)\nlargest_3['user_id'] = test_ids\nlargest_3_long = pd.melt(largest_3,id_vars=\"user_id\",var_name=\"sequence\", value_name=\"challenge\" )\nlargest_3_long['sequence'] = largest_3_long['sequence'].map({0:'11',1:'12',2:\"13\"})\nlargest_3_long['user_sequence'] = largest_3_long['user_id'].map(str)+\"_\"+largest_3_long['sequence'].map(str)\nlargest_3_long.challenge[largest_3_long.challenge == \"\"] = \"CI25555\"\nlargest_3_long[['user_sequence','challenge']].to_csv(\"submission_lstm3.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}