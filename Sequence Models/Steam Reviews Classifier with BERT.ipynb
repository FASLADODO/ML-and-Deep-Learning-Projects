{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Steam Reviews Classifier with BERT\nHere Iâ€™ll try to show how BERT handles the classification of reviews in Steam. For the BERT part, I will use [xhlulu](https://www.kaggle.com/xhlulu) code."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\nimport tokenization\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir('/kaggle')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/steam-reviews/train.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.user_suggestion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most reviews are positive"},{"metadata":{"trusted":true},"cell_type":"code","source":"sizes = [data.user_suggestion.value_counts()[0], data.user_suggestion.value_counts()[1]]\nlabels = [0, 1]\n\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots()\nax1.set_title('Games recommendation')\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data['hour_played_reviews'] = data.groupby('hour_played')['hour_played'].transform('count')\n#x = data.hour_played\n#y = data['hour_played_reviews']\n#fig = plt.figure(figsize = (13,8))\n#ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n#ax.scatter(x,y)\n#ax.set_title('Dependence of the number of ratings on the duration of the game')\n#ax.set_xlabel('Hours played')\n#ax.set_ylabel('Number of reviews')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph looks ugly, but we can see here that a greater number of reviews are made by players who played only a few hours, and very few reviews where players played for really long."},{"metadata":{"trusted":true},"cell_type":"code","source":"#top_reviewed_games = data.title.value_counts()\n#print('Top 10 reviewed games:\\n\\n{}'.format(data.title.value_counts()[:10]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data contain reviews from Steam's best selling games as February 2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.assign(y = (data.user_suggestion == 1).astype(int))\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data)/2)\ndata_cut = data.copy() # We will use just a small portion of data \ndata_cut.tail(1)         # because BERT with a full data size will work for a very long time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cut.user_review = [str(x) for x in data_cut.user_review.values] # So that there are no problems in the tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef clean_tweets(lst):\n    # remove twitter Return handles (RT @xxx:)\n    lst = np.vectorize(remove_pattern)(lst, \"RT @[\\w]*:\")\n    # remove twitter handles (@xxx)\n    lst = np.vectorize(remove_pattern)(lst, \"@[\\w]*\")\n    # remove URL links (httpxxx)\n    lst = np.vectorize(remove_pattern)(lst, \"https?://[A-Za-z0-9./]*\")\n    # remove special characters, numbers, punctuations (except for #)\n    lst = np.core.defchararray.replace(lst, \"[^a-zA-Z#]\", \" \")\n    # remove special characters, numbers, punctuations (except for #)\n    lst = np.core.defchararray.replace(lst, \"[^a-zA-Z#]\", \" \")  \n    # remove amp with and\n    lst = np.vectorize(replace_pattern)(lst, \"amp\", \"and\")      \n    return lst\ndef remove_pattern(input_txt, pattern):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, '', input_txt)        \n    return input_txt\ndef replace_pattern(input_txt, pattern, replace_text):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, replace_text, input_txt)        \n    return input_txt\ndef clean_hashtags(lst):\n    lst = np.vectorize(remove_pattern)(lst, \"#[A-Za-z0-9]+\")\n    lst = np.vectorize(remove_pattern)(lst, \"#[\\w]*\")\n    return lst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    phrase = re.sub(r\"early access review\", \"early access review \", phrase)\n    phrase = re.sub(r\"\\+\", \" + \", phrase) \n    phrase = re.sub(r\"\\-\", \" - \", phrase)     \n    phrase = re.sub(r\"/10\", \"/10 \", phrase)     \n    phrase = re.sub(r\"10/\", \" 10/\", phrase)         \n    return phrase\n\n\ntrial = \"Hey I'm Yann, how're you and how's it going ? That's interesting: I'd love to hear more about it+info\"\nprint(decontracted(trial))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n# Define function to lemmatize each word with its POS tag\ndef lemmatize_with_postag(sentence):\n    sent = TextBlob(sentence)\n    tag_dict = {\"J\": 'a', \n                \"N\": 'n', \n                \"V\": 'v', \n                \"R\": 'r'}\n    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n    return \" \".join(lemmatized_list)\n\n# Lemmatize\nsentence = \"The striped bats are hanging on their feet for best\"\nlemmatize_with_postag(sentence)\n#> 'The striped bat be hang on their foot for best'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text2 = list(train3['user_review'].astype('str'))\ntext2 = clean_tweets(data_cut.user_review)\ntext3 = [ta.lower() for ta in text2]\ntext4 = [''.join([i if ord(i) < 128 else ' ' for i in t]) for t in text3]\ntext5 = [decontracted(u) for u in text4]\n#text6 = [lemmatize_with_postag(u) for u in text5]\ntext5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cut.user_review = text5\ndata_cut.user_review = [str(x) for x in data_cut.user_review.values] # So that there are no problems in the tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cut.user_review.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data_cut.user_review\ny = data_cut.y\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 42, test_size=0.2)\nfor each in [y_train, y_test]:\n    print(f\"y fraction = {each.mean():.4f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We check how identical we got the parts. If the difference is big, you need to try mixing the data with another method. However, now we have a very good ratio."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train : {}, Test: {}'.format(len(X_train),len(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test = X_test[:-2] # if it's not equal\n#y_test = y_test[:-2]\n#X_train = X_train[:-1]\n#y_train = y_train[:-1]\nprint('\\n train X: {} \\n train y: {} \\n Val X: {} \\n val y: {}'.format(len(X_train),len(y_train),len(X_test),len(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodule_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/2\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encode(input_text, tokenizer, max_len = 512):\n    token_input = [] \n    mask_input = []\n    seg_input = []\n    \n    for text in input_text:\n        text = tokenizer.tokenize(text)\n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)      \n        token_input.append(tokens + [0]*pad_len)\n        mask_input.append([1]*len(input_sequence) + [0]*pad_len)\n        seg_input.append([0] * max_len)\n        \n    return np.array(token_input), np.array(mask_input), np.array(seg_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(bert_layer, max_len = 512):\n    input_word_ids = Input(shape=(max_len, ),dtype = tf.int32,name = 'input_words_ids')\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    \n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    out2 = Dense(8, activation='relu')(clf_output)\n    out = Dense(1, activation = 'sigmoid')(out)\n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_input = bert_encode(X_train.values, tokenizer, max_len=160)\ntest_input = bert_encode(X_test.values, tokenizer, max_len=160)\ntrain_labels = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(bert_layer, max_len=160)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_history = model.fit(\n    train_input, train_labels,\n    validation_split=0.2,\n    epochs=5,\n    batch_size=4\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/model2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_input)\npreds = []\nfor x in prediction:\n    preds.append(int(x.round()))\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy: \", accuracy_score(preds, y_test.values))\n\nfrom sklearn.metrics import f1_score\nprint(\"F1_Score: \", f1_score(preds, y_test.values, average = 'weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = pd.read_csv(\"/kaggle/input/steam-reviews-test-dataset/test.csv\")\ndata2.user_review = [str(x) for x in data2.user_review.values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text2 = list(train3['user_review'].astype('str'))\ntext_test2 = clean_tweets(data2.user_review)\ntext_test3 = [ta.lower() for ta in text_test2]\ntext_test4 = [''.join([i if ord(i) < 128 else ' ' for i in t]) for t in text_test3]\ntext_test5 = [decontracted(u) for u in text_test4]\n#text6 = [lemmatize_with_postag(u) for u in text5]\ntext_test5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.user_review = text_test5\ndata2.user_review = [str(x) for x in data2.user_review.values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_input = bert_encode(data2.user_review.values, tokenizer, max_len=160)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_final = model.predict(final_test_input)\npreds_final = []\nfor x in prediction_final:\n    preds_final.append(int(x.round()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'review_id': data2.review_id, 'user_suggestion': preds_final})\nsubmission.to_csv(\"/kaggle/working/submission_bert2.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad for lazy model without data cleaning"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}